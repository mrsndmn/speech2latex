{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f55fc92-fb53-4d93-ad7f-040cbec64e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer \n",
    "from transformers.generation import GenerationConfig\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "from IPython.display import Latex, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2bc7c07e-f19b-4136-8d2c-588a071581a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6ed974-22ea-4ed6-8ddd-6b673b2c13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5085d8a4-0f03-4d4a-a076-6aee1b03e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc454d52-1880-4829-a681-f1794b5fa126",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_head_state_dict = torch.load('ckpts/asr-sentence/version_0/lm_head_state_dict.pth', weights_only=False, map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694bd5cb-3696-4776-8807-88ad13ecaf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac2de2c90f42a0b9462a9eb46fb13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-Audio\", trust_remote_code=True)\n",
    "\n",
    "# use bf16\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "# use fp16\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio\", device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
    "# use cpu only\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio\", device_map=\"cpu\", trust_remote_code=True).eval()\n",
    "# use cuda device\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio\", device_map=DEVICE, trust_remote_code=True).eval()\n",
    "\n",
    "eos_token_id = tokenizer('<|endoftext|>',return_tensors='pt').input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e8d677-c21b-401f-8e42-b2e30f3507b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.load_state_dict(lm_head_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64fe1e05-2d4b-41f5-a11e-6026123f6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e54f832-d9e4-4aa3-876b-9cb2707402ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>language</th>\n",
       "      <th>formula_id</th>\n",
       "      <th>is_tts</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>whisper_transcription</th>\n",
       "      <th>latex</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4178</td>\n",
       "      <td>0</td>\n",
       "      <td>mu minus nu hat.</td>\n",
       "      <td>Mu hat minus Nu hat.</td>\n",
       "      <td>\\hat \\mu-\\hat \\nu</td>\n",
       "      <td>/workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4231</td>\n",
       "      <td>0</td>\n",
       "      <td>mu tilde is defined as the set of mu one plus ...</td>\n",
       "      <td>MuTiled is defined as the set of Mu 1 plus Mu...</td>\n",
       "      <td>\\tilde { \\mu } : = \\ { \\mu_1 + \\tilde { \\mu } ...</td>\n",
       "      <td>/workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4321</td>\n",
       "      <td>0</td>\n",
       "      <td>N sub G of s sub 1 union N sub G of s sub 2 se...</td>\n",
       "      <td>NG union NG set- open brace C1, C2 close brace</td>\n",
       "      <td>N_G ( s_1 ) \\cup N_G ( s_2 ) \\setminus \\ { s_1...</td>\n",
       "      <td>/workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4374</td>\n",
       "      <td>0</td>\n",
       "      <td>N, open parenthesis, 1 sub Q transpose, comma,...</td>\n",
       "      <td>n 1 sub q transpose comma 4 sub i sub n close...</td>\n",
       "      <td>\\mathcal { N } \\left ( { 1_Q^ \\top,4 { I_n } }...</td>\n",
       "      <td>/workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4507</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative zeta to the power of negative one-hal...</td>\n",
       "      <td>negative zeta to the power of negative one ha...</td>\n",
       "      <td>\\mathfrak { C } = [ -\\zeta^ { -1/2 } , \\zeta^ ...</td>\n",
       "      <td>/workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker_id language  formula_id  is_tts  \\\n",
       "0           0      eng        4178       0   \n",
       "1           0      eng        4231       0   \n",
       "2           0      eng        4321       0   \n",
       "3           0      eng        4374       0   \n",
       "4           0      eng        4507       0   \n",
       "\n",
       "                                       pronunciation  \\\n",
       "0                                   mu minus nu hat.   \n",
       "1  mu tilde is defined as the set of mu one plus ...   \n",
       "2  N sub G of s sub 1 union N sub G of s sub 2 se...   \n",
       "3  N, open parenthesis, 1 sub Q transpose, comma,...   \n",
       "4  Negative zeta to the power of negative one-hal...   \n",
       "\n",
       "                               whisper_transcription  \\\n",
       "0                              Mu hat minus Nu hat.    \n",
       "1   MuTiled is defined as the set of Mu 1 plus Mu...   \n",
       "2    NG union NG set- open brace C1, C2 close brace    \n",
       "3   n 1 sub q transpose comma 4 sub i sub n close...   \n",
       "4   negative zeta to the power of negative one ha...   \n",
       "\n",
       "                                               latex  \\\n",
       "0                                  \\hat \\mu-\\hat \\nu   \n",
       "1  \\tilde { \\mu } : = \\ { \\mu_1 + \\tilde { \\mu } ...   \n",
       "2  N_G ( s_1 ) \\cup N_G ( s_2 ) \\setminus \\ { s_1...   \n",
       "3  \\mathcal { N } \\left ( { 1_Q^ \\top,4 { I_n } }...   \n",
       "4  \\mathfrak { C } = [ -\\zeta^ { -1/2 } , \\zeta^ ...   \n",
       "\n",
       "                                          audio_path  \n",
       "0  /workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...  \n",
       "1  /workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...  \n",
       "2  /workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...  \n",
       "3  /workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...  \n",
       "4  /workspace-SR006.nfs2/shares/SR006.nfs2/Nikita...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =pd.read_csv('test_ENG.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5f675959-84ae-4863-87ca-cd0ef591cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b12f13d3-f91c-41fb-a382-cb01a488cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_url = \"../2646.wav\"\n",
    "# audio_url = \"../4763.wav\"\n",
    "audio_url = test.iloc[N]['audio_path']\n",
    "true_latex = test.iloc[N]['latex']\n",
    "sp_prompt = \"<|startofanalysis|><|en|><|caption|><|en|><|notimestamps|><|wo_itn|>\"\n",
    "query = f\"<audio>{audio_url}</audio>{sp_prompt}\"\n",
    "audio_info = tokenizer.process_audio(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d5e2643-c6c0-4354-a1d7-05994764ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(query, return_tensors='pt', audio_info=audio_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "49125cba-bf6a-48b6-84db-a5e8180d80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params = {\n",
    "    \"max_new_tokens\": 50,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"remove_invalid_values\": True,\n",
    "    \"eos_token_id\": eos_token_id,\n",
    "    \"forced_eos_token_id\": eos_token_id,\n",
    "    \"use_cache\": True,\n",
    "    \"no_repeat_ngram_size\": 4,\n",
    "    # \"num_return_sequences\": 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc11a8ac-aa50-4052-94e6-3d1af37e35ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/skripkin/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/jovyan/.mlspace/envs/skripkin/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:623: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "/home/jovyan/.mlspace/envs/skripkin/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:649: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<audio>/workspace-SR006.nfs2/shares/SR006.nfs2/Nikita/speech2latex/TagMePools/eng/pool4_eng/6aba0f6b-abcf-4045-b529-f3f905474093/6695.wav</audio><|startofanalysis|><|en|><|caption|><|en|><|notimestamps|><|wo_itn|>A \\mathbf{v} \\in \\mathbf{T}_\\mathbf{u} \\mathbf{n} \\to \\mathbf{x} \\in S^2 \\to \\lambda \\mathbf{i} \\in T<|endoftext|>\n",
      "A \\mathbf{v} \\in \\mathbf{T}_\\mathbf{u} \\mathbf{n} \\to \\mathbf{x} \\in S^2 \\to \\lambda \\mathbf{i} \\in T\n"
     ]
    }
   ],
   "source": [
    "inputs = inputs.to(model.device)\n",
    "pred = model.generate(**inputs, **gen_params, audio_info=audio_info)\n",
    "response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=False, audio_info=audio_info)\n",
    "print(response)\n",
    "wo_ind = response.find('<|wo_itn|>')\n",
    "response = response[wo_ind:].replace('<|endoftext|>', '').replace('<|wo_itn|>', '')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6a7ab4b3-4e40-40fb-ad9e-9b9ba2d231cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$A \\mathbf{v} \\in \\mathbf{T}_\\mathbf{u} \\mathbf{n} \\to \\mathbf{x} \\in S^2 \\to \\lambda \\mathbf{i} \\in T$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(f'${response}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5cc7a325-84a4-43f7-a97c-5c773407535c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$A_\\mu \\rightarrow A_\\mu + \\partial_\\mu \\lambda$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(f'${true_latex}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f888e4e-327c-457e-a913-460227ddf8ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9cb904c1374cc38f1d7b279177e4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = []\n",
    "for i in tqdm(range(len(test))):\n",
    "    audio_url = test.iloc[N]['audio_path']\n",
    "    true_latex = test.iloc[N]['latex']\n",
    "    sp_prompt = \"<|startofanalysis|><|en|><|caption|><|en|><|notimestamps|><|wo_itn|>\"\n",
    "    query = f\"<audio>{audio_url}</audio>{sp_prompt}\"\n",
    "    audio_info = tokenizer.process_audio(query)\n",
    "    inputs = tokenizer(query, return_tensors='pt', audio_info=audio_info)\n",
    "    inputs = inputs.to(model.device)\n",
    "    pred = model.generate(**inputs, **gen_params, audio_info=audio_info)\n",
    "    response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=False, audio_info=audio_info)\n",
    "    # print(response)\n",
    "    wo_ind = response.find('<|wo_itn|>')\n",
    "    response = response[wo_ind:].replace('<|endoftext|>', '').replace('<|wo_itn|>', '')\n",
    "    # print(response)\n",
    "\n",
    "    outputs.append({\n",
    "        'pred': response,\n",
    "        'true_latex': true_latex\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bec8c-52e4-4a4a-b858-7915fe1475d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(outputs, 'outputs_lm_head_trained_1_epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "044817d9-dbac-445d-831d-643713f6cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69869622-1c78-43cb-bbbc-5f8414ed4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd28f2-0eb0-415c-b361-63f576e220c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-skripkin]",
   "language": "python",
   "name": "conda-env-.mlspace-skripkin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
