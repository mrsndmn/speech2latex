# speech2latex_in_context_dataset


## Links

Данные из 100 первых шардов [из proof-pile-2/arxiv](https://huggingface.co/datasets/EleutherAI/proof-pile-2/tree/main/arxiv/train)

* [latex_in_context_14M.jsonl](https://storage.yandexcloud.net/speech2latex-in-context/latex_in_context_14M.jsonl) -- all processed arxiv shards
* [latex_in_context_100k.jsonl](https://storage.yandexcloud.net/speech2latex-in-context/latex_in_context_100k.jsonl) -- sampled from `latex_in_context_14M.jsonl`
* [latex_in_context_15k.jsonl](https://storage.yandexcloud.net/speech2latex-in-context/latex_in_context_15k.jsonl) -- sampled from `latex_in_context_100k.jsonl`


Источник такой же, как предыдущий, но оставили только статьи с 2019 года. **Важно!** Сэмплирование рандомное, пересечения с предыдущим файликом не гарантируются.
* [latex_in_context_since_2019_15k.jsonl](https://storage.yandexcloud.net/speech2latex-in-context/latex_in_context_since_2019_15k.jsonl)
* [latex_in_context_since_2019_100k.jsonl](https://storage.yandexcloud.net/speech2latex-in-context/latex_in_context_since_2019_100k.jsonl)
* [latex_in_context_since_2019_7M.jsonl](https://storage.yandexcloud.net/speech2latex-in-context/latex_in_context_since_2019_7M.jsonl)
